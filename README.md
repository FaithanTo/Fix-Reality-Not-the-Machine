# Fix Reality, Not the Machine

**A positional analysis of algorithmic fairness through the Northpointe (COMPAS) vs. ProPublica debate.**

*This analysis was originally developed as part of my coursework in the MSBA program at the University of Minnesota Carlson School of Management.*

This small project explores the ethical and statistical tension between fairness, transparency, and systemic bias in machine learning tools used in criminal justice. Using Python in a Jupyter Notebook, I broke down the COMPAS risk scoring model, evaluated both ProPublicaâ€™s critique and Northpointe's defense, and reflected on the deeper question: should we fix biased algorithms, or the biased systems they're meant to reflect?

## ðŸ”§ Tools Used
- Jupyter Notebook
- Python: Pandas, Statsmodels, Scikit-learn, Matplotlib
- Exploratory data analysis (EDA)
- Narrative commentary and interpretability discussion

## ðŸ’¡ Key Themes
- Algorithmic bias
- Predictive risk assessment
- Societal consequences of using Recall vs. Precision

> "Sometimes, improving a machine learning model means changing the environment it was trained on."